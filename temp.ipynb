{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1660cc-0612-45a9-9ef2-ed660c4a6f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-level dictionary file 'word_level_dictionary.txt' created successfully.\n"
     ]
    }
   ],
   "source": [
    "!python utils/wordlevel_dict.py tokenized-java-cs.txt forward.align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1dd26-e8cc-49ee-ad7d-651406032045",
   "metadata": {},
   "source": [
    " ### Check the high probability outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bcfd12e-4ea5-4144-8f25-19c69d62ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_high_probability_lines(input_file: str, output_file: str, prob_threshold: float = 0.5, count_threshold: int = 1):\n",
    "    # Regular expressions to match probability and count\n",
    "    prob_pattern = re.compile(r'Probability\\s*=\\s*([\\d\\.]+)')\n",
    "    count_pattern = re.compile(r'Count\\s*=\\s*(\\d+)')\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            # Search for probability and count using regex\n",
    "            prob_match = prob_pattern.search(line)\n",
    "            count_match = count_pattern.search(line)\n",
    "\n",
    "            if prob_match and count_match:\n",
    "                # Extract the probability and count values\n",
    "                probability = float(prob_match.group(1))\n",
    "                count = int(count_match.group(1))\n",
    "\n",
    "                # Check if both probability and count exceed their respective thresholds\n",
    "                if probability > prob_threshold and count > count_threshold:\n",
    "                    outfile.write(line)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_file_path = 'word_level_dictionary.txt'  # Path to your input file\n",
    "    output_file_path = 'high_probability_lines.txt'  # Path for the output file\n",
    "    probability_threshold = 0.5  # Probability threshold\n",
    "    count_threshold = 10  # Count threshold\n",
    "\n",
    "    filter_high_probability_lines(input_file_path, output_file_path, probability_threshold, count_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f0279-276c-40d2-b8ce-3bb91e0881b0",
   "metadata": {},
   "source": [
    "### Prepare the files for qcri pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a74ac76-8a03-4315-a0c6-92417c3bb240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/instruction/coms-599-29-f24/group_4_clustering/.conda/envs/neurox_pip/lib/python3.8/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language.build_library is deprecated. Use the new bindings instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_align/tree-sitter/tokenize_corpus.py\", line 5, in <module>\n",
      "    Language.build_library(\n",
      "  File \"/work/instruction/coms-599-29-f24/group_4_clustering/.conda/envs/neurox_pip/lib/python3.8/site-packages/tree_sitter/__init__.py\", line 81, in build_library\n",
      "    source_mtimes = [path.getmtime(__file__)] + [path.getmtime(path_) for path_ in source_paths]\n",
      "  File \"/work/instruction/coms-599-29-f24/group_4_clustering/.conda/envs/neurox_pip/lib/python3.8/site-packages/tree_sitter/__init__.py\", line 81, in <listcomp>\n",
      "    source_mtimes = [path.getmtime(__file__)] + [path.getmtime(path_) for path_ in source_paths]\n",
      "  File \"/work/instruction/coms-599-29-f24/group_4_clustering/.conda/envs/neurox_pip/lib/python3.8/genericpath.py\", line 55, in getmtime\n",
      "    return os.stat(filename).st_mtime\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'tree-sitter-java/src/parser.c'\n"
     ]
    }
   ],
   "source": [
    "!python utils/split.py tokenized-java-cs.txt Data/Java-CS/input.in Data/Java-CS/label.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurox_pip",
   "language": "python",
   "name": "neurox_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
